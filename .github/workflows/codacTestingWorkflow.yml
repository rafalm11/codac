name: codacTestingWorkflow

# Controls when the workflow will run
on:
  push:
    branches: [ "dev" ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

jobs:
  unitTest:
    runs-on: ubuntu-latest
    steps:
      - name: code checkout
        uses: actions/checkout@v3
        
      - name: python setup
        uses: actions/setup-python@v4
        with:
          python-version: '3.7'
          
      - name: application dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          mkdir src/logs
        
      - name: install test dependencies
        run: pip install -r requirements_test.txt
        
      - name: run unit test
        run: |
          cd src
          python -m pytest ../tests

      - name: unit test finished
        run: echo unit tests finished

  E2ETest:
    runs-on: ubuntu-latest
    steps:
      - name: code checkout
        uses: actions/checkout@v3
        
      - name: python setup
        uses: actions/setup-python@v4
        with:
          python-version: '3.7'
          
      - name: install pip package
        run: python -m pip install --upgrade pip

      - name: install build package
        run: python -m pip install build

      - name: building codacJoiner
        run: python -m build

      - name: install codacJoiner package
        run: |
          pip install ./dist/codacJoiner-1.0.0.tar.gz
          pip list
        
      - name: application test run
        run: |
          pwd        
          cd src
          pwd   
          mkdir logs       
          ls
          python codac.py -p '../tests/client_input/dataset_one.csv' -a '../tests/client_input/dataset_two.csv'

      - name: compare expected result (no diff expected)
        run: |
          
          diff -q ../tests/expected_client_data/part*.csv client_data/part*.csv

      - name: application failing test run
        run: |
          pwd
          cd temp
          pwd
          ls
          python codac.py -p '../tests/client_input/dataset_one.csv' -a '../tests/client_input/dataset_two.csv' -c 'United Kingdom'

      - name: compare expected result (diff expected)
        run: |
          pwd
          cd temp
          pwd
          ls
          if diff -q ../tests/expected_client_data/part*.csv client_data/part*.csv; then
            echo no differences. bad
            exit 1
          else
            echo found differences. ok
          fi

      - name: E2E finished
        run: echo E2E tests finished
